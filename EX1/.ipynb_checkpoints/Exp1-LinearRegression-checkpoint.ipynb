{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验1：线性回归及岭回归\n",
    "----------\n",
    "## 介绍\n",
    "\n",
    "在本实验中，你将实现线性回归及岭回归并了解其在数据上的工作原理。\n",
    "\n",
    "本次实验需要用到的数据集包括：\n",
    "\n",
    "- ex1data1.txt -单变量的线性回归数据集\n",
    "- ex1data2.txt -多变量的线性回归数据集\n",
    "\n",
    "评分标准如下：\n",
    "\n",
    "- [要点1：计算损失](#1)-------------------------------（20分）\n",
    "- [要点2：单变量线性回归梯度下降](#2)----------（20分）\n",
    "- [要点3：数据标准化](#3)----------------------------（20分）\n",
    "- [要点4：多变量线性回归梯度下降](#4)----------（20分）\n",
    "- [要点5：线性回归闭式解](#5)----------------------（10分）\n",
    "- [要点6：岭回归闭式解](#6)-------------------------（10分）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 单变量线性回归\n",
    "\n",
    "在该部分实验中，将实现单变量线性回归并用来预测餐车的利润。\n",
    "\n",
    "假设你是一家餐厅的领导，正在考虑在不同的城市开设新的分店。该连锁店已经在不同的城市有了餐车，并且你能够获得每个城市的人口和利润数据。\n",
    "\n",
    "现在需要使用这些数据来帮助你选择下一个被扩展的城市。\n",
    "\n",
    "文件`ex1data1.txt`包含线性回归问题的数据集。第一列数据对应城市人口，第二列数据对应那座城市的餐车的利润。利润为负时表示亏损。\n",
    "\n",
    "### 1.1 绘制数据<span id='2'></span>\n",
    "\n",
    "在开始进入实验之前，对数据进行可视化通常很有用。对于该数据集，可以使用散点图进行可视化，因为它只有两个属性（人口、利润）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入所需要的库文件\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.3829</td>\n",
       "      <td>11.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.4764</td>\n",
       "      <td>4.3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.5781</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.4862</td>\n",
       "      <td>6.5987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0546</td>\n",
       "      <td>3.8166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Population   Profit\n",
       "0      6.1101  17.5920\n",
       "1      5.5277   9.1302\n",
       "2      8.5186  13.6620\n",
       "3      7.0032  11.8540\n",
       "4      5.8598   6.8233\n",
       "5      8.3829  11.8860\n",
       "6      7.4764   4.3483\n",
       "7      8.5781  12.0000\n",
       "8      6.4862   6.5987\n",
       "9      5.0546   3.8166"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据存储路径\n",
    "path = 'ex1data1.txt'\n",
    "\n",
    "# 读入相应的数据文件\n",
    "data = pd.read_csv(path, header=None,names=['Population','Profit'])\n",
    "\n",
    "#查看数据的前五条\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Population', ylabel='Profit'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据可视化 \n",
    "data.plot(kind='scatter', x='Population', y='Profit',c='red', figsize=(9,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 梯度下降\n",
    "\n",
    "在该部分中，将使用梯度下降来选择合适的线性回归参数$\\mathbf{w}$用以拟合给定数据集。\n",
    "\n",
    "说明：为编写方便，偏置项$b$可被作为权重向量$\\mathbf{w}$的第一个分量$w_0$。\n",
    "\n",
    "#### 1.2.1 目标函数\n",
    "\n",
    "线性回归的目的是最小化目标函数：\n",
    "\n",
    "$$ E(\\mathbf{w}) = \\frac{1}{2m} \\sum_{i=1}^m \\left( \\mathbf{w}^T\\mathbf{x}_i - y_i\\right)^2$$\n",
    "\n",
    "其中$\\mathbf{w}$为权重参数。上述目标函数也可写成如下矩阵形式：\n",
    "\n",
    "$$ E(\\mathbf{w}) = \\frac{1}{2m} \\|\\mathbf{X}\\mathbf{w}-\\mathbf{y}\\|_2^2$$\n",
    "\n",
    "其中矩阵$\\mathbf{X}$的第$i$行是$\\mathbf{x}_i^T$。 \n",
    "\n",
    "回顾一下，模型的参数向量是$\\mathbf{w}$，这些将用来调整以最小化损失函数$E(\\mathbf{w})$。\n",
    "\n",
    "其中一种方法是使用批量梯度下降算法，在批量梯度下降中，每次迭代地执行更新，随着梯度下降的每一步计算，参数$\\mathbf{w}$越来越接近能够使得损失函数$E(\\mathbf{w})$达到最低的最佳值。\n",
    "\n",
    "\n",
    "#### 1.2.2 实现\n",
    "\n",
    "在上一部分的代码中，我们已经将所需要用到的数据加载至变量`data`中，并为其列分别进行命名。\n",
    "\n",
    "接下来，我们在数据中添加了一个维度来拟合截距项$w_0$。并将初始参数值设为0，学习率$\\alpha$设为0.01。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ones</th>\n",
       "      <th>Population</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.1101</td>\n",
       "      <td>17.5920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.5277</td>\n",
       "      <td>9.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5186</td>\n",
       "      <td>13.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7.0032</td>\n",
       "      <td>11.8540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5.8598</td>\n",
       "      <td>6.8233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>8.3829</td>\n",
       "      <td>11.8860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7.4764</td>\n",
       "      <td>4.3483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5781</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>6.4862</td>\n",
       "      <td>6.5987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>5.0546</td>\n",
       "      <td>3.8166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ones  Population   Profit\n",
       "0     1      6.1101  17.5920\n",
       "1     1      5.5277   9.1302\n",
       "2     1      8.5186  13.6620\n",
       "3     1      7.0032  11.8540\n",
       "4     1      5.8598   6.8233\n",
       "5     1      8.3829  11.8860\n",
       "6     1      7.4764   4.3483\n",
       "7     1      8.5781  12.0000\n",
       "8     1      6.4862   6.5987\n",
       "9     1      5.0546   3.8166"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在列索引为0处添加数据列，该列值均为1\n",
    "data.insert(0, 'Ones', 1)\n",
    "\n",
    "#获取数据列数\n",
    "cols = data.shape[1]\n",
    "\n",
    "#对变量X和y进行初始化,并将其数据类型转换为矩阵\n",
    "X = data.iloc[:,0:cols-1]\n",
    "y = data.iloc[:,cols-1:cols]\n",
    "X = np.matrix(X.values)\n",
    "y = np.matrix(y.values)\n",
    "\n",
    "#学习率、迭代次数的初始化\n",
    "alpha = 0.01\n",
    "iterations = 1500\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2.3 计算损失函数 $E(\\mathbf{w})$<span id='3'></span>\n",
    "\n",
    "在执行梯度下降最小化成本函数$E(\\mathbf{w})$时，通过计算成本来监视收敛状态是有帮助的。\n",
    "\n",
    "在该部分练习任务中，**你需要实现一个计算损失$E(\\mathbf{w})$的函数`computeCost`**，用于检查梯度下降实现的收敛性。\n",
    "\n",
    "其中，$\\mathbf{X}$ 和 $\\mathbf{y}$ 不是标量值，而是矩阵，其行代表训练集中的示例。\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**要点 1：**\n",
    "完成该函数后，将$\\mathbf{w}$值初始化为$\\mathbf{0}$并进行损失函数的计算，将得到的损失函数值打印出来。\n",
    "\n",
    "如果结果为32.07，则计算通过。\n",
    "</div>\n",
    "\n",
    "<a id=\"computeCost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (566322771.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Temp\\ipykernel_13808\\566322771.py\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    w = np.matrix(np.zeros((2,1)))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "# ====================== 在这里填入代码 ======================= \n",
    "def computeCost(X, y, w):\n",
    "     \n",
    "\n",
    "\n",
    "w = np.matrix(np.zeros((2,1)))\n",
    "computeCost(X, y, w)\n",
    "# ============================================================= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.4 梯度下降<span id='4'></span>\n",
    "\n",
    "接下来，我们将实现梯度下降，给出的代码已经实现了循环结构，你只需要在每次的迭代中提供$\\mathbf{w}$的更新。\n",
    "\n",
    "在进行代码实现时，请确保你了解要优化的内容，和正在更新的内容。\n",
    "\n",
    " \n",
    "验证梯度下降是否正常工作的一种好方法是查看$E(\\mathbf{w})$的值，并检查该值每步是否减小。每次迭代时，代码都会调用`computeCost`函数并打印损失函数值。假设你实现了梯度下降，正确地计算损失，$E(\\mathbf{w})$值一般会在算法结束时收敛到稳定值。\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**要点 2：**\n",
    "\n",
    "你的任务是实现单变量线性回归的梯度下降。最终的损失函数值应约为4.48。\n",
    "\n",
    "</div>\n",
    "\n",
    "<a id=\"computeCost\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (2727955604.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Temp\\ipykernel_13808\\2727955604.py\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    return w, cost\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "##====================== 在这里填入代码 ======================= \n",
    "def gradientDescent(X, y, w, alpha, iters):\n",
    "    cost = np.zeros(iters)\n",
    "    \n",
    "    for i in range(iters):\n",
    "\n",
    "        \n",
    "    return w, cost\n",
    "##============================================================= \n",
    "\n",
    "w_final, cost_final = gradientDescent(X, y, w, alpha, iterations)\n",
    "# 计算最终的参数所得到的成本值\n",
    "print('The weight vector:\\n',w_final)\n",
    "computeCost(X, y, w_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对拟合曲线进行绘制\n",
    "x = np.linspace(data.Population.min(), data.Population.max(), 100)\n",
    "f = w_final[0,0] + (w_final[1,0] * x)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.plot(x, f, 'b', label='Prediction')\n",
    "ax.scatter(data.Population, data.Profit, c='red',label='Traning Data')\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('Population')\n",
    "ax.set_ylabel('Profit')\n",
    "ax.set_title('Predicted Profit vs. Population Size')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 可视化损失函数\n",
    "\n",
    "为了更好地理解损失函数的迭代计算，将每一步计算的cost值进行记录并绘制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.plot(np.arange(iterations), cost_final, 'r')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_title('Error vs. Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 多变量线性回归\n",
    "\n",
    "在该部分中，将使用多个变量来实现用线性回归预测房屋价格。假设你目前正在出售房屋，想知道什么是好的市场价格。\n",
    "\n",
    "一种方法是首先收集最近出售房屋的信息，其次是建立房屋价格模型。\n",
    "\n",
    "文件`ex1data2.txt`包含俄勒冈州波特兰市的房屋价格及相关信息。第一列是房屋的大小（以平方英尺为单位），第二列是卧室的个数，第三列是房屋的价格。\n",
    "\n",
    "### 2.1 特征标准化\n",
    "\n",
    "以下代码将从文件`ex1data2.txt`文件中加载并显示该数据集。\n",
    "\n",
    "通过观察这些数据，可以发现房屋的大小大约是卧室数量的1000倍。而当不同的特征值之间相差几个数量级时，将**特征进行缩放可以使梯度下降收敛得更快**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'ex1data2.txt'\n",
    "data2 = pd.read_csv(path, header=None, names=['Size', 'Bedrooms', 'Price'])\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span id='5'></span>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**要点 3**：\n",
    "\n",
    "在该部分实验中，你的任务是**编写代码并实现数据集中的数据标准化**。\n",
    "\n",
    "</div>\n",
    "\n",
    "<a id=\"computeCost\"></a>\n",
    "\n",
    "- 从数据集中减去每个特征的平均值。\n",
    "\n",
    "- 减去平均值后，再将新的特征值除以各自的“标准差”\n",
    "\n",
    "标准差是一种衡量特定特征的值的范围内有多大变化的方法（大多数数据点将位于平均值的两个标准差内）；这是取值范围的替代方法。\n",
    "\n",
    "当标准化特征时，需要存储用于标准化的值——平均值和标准差。从模型中学习参数后，经常需要预测新的房屋的价格。此时给定一个新的$x$值（房屋面积和卧室数量），必须首先使用先前从训练集中计算的平均值和标准差来对新的数据进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##====================== 在这里填入代码 =======================\n",
    "\n",
    "data2.head()\n",
    "##============================================================= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#在列索引为0处添加数据列，该列值均为1\n",
    "data2.insert(0, 'Ones', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 梯度下降<span id='6'></span>\n",
    "\n",
    "在之前的练习中，我们使用单变量线性回归实现了梯度下降的问题。\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**要点 4：**\n",
    "\n",
    "假设函数和批次梯度下降的更新规则保持不变，你的任务是**代码实现多变量线性回归的梯度下降**。最终的损失函数值应大约为0.13。\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    " \n",
    "- 确保你的代码中可以支持任何大小的数据，并且数据均已被向量化。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X (training data) and y (target variable)\n",
    "cols = data2.shape[1]\n",
    "X2 = data2.iloc[:,0:cols-1]\n",
    "y2 = data2.iloc[:,cols-1:cols]\n",
    "\n",
    "##====================== 在这里填入代码 ======================= \n",
    "\n",
    "# convert to matrices and initialize theta\n",
    " \n",
    "\n",
    "# perform linear regression on the data set\n",
    " \n",
    "##============================================================= \n",
    "# get the cost (error) of the model\n",
    "print('The weight vector:\\n',w2_final)\n",
    "computeCost(X2, y2, w2_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化损失函数\n",
    "fig, ax = plt.subplots(figsize=(9,6))\n",
    "ax.plot(np.arange(iterations), cost2_final, 'r')\n",
    "ax.set_xlabel('Iterations')\n",
    "ax.set_ylabel('Cost')\n",
    "ax.set_title('Error vs. Iterations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 闭式解<span id='6'></span>\n",
    "\n",
    "通过令损失函数关于w的梯度为0，可得到线性回归原问题的闭式解\n",
    "\n",
    "$$ \\mathbf{w}= (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "梯度下降与闭式解的比较：\n",
    "\n",
    "梯度下降：需要选择学习率$\\alpha$，需要多次迭代\n",
    "\n",
    "闭式解：不需要选择学习率$\\alpha$，一次计算得出；但是需要计算矩阵的逆，当样本数量$n$较大时运算代价较大\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**要点 5：**\n",
    "\n",
    "你的任务是**代码实现多变量线性回归的闭式解**。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###线性回归闭式解###\n",
    "def LinearRegression(X, y):\n",
    "##====================== 在这里填入代码 ======================= \n",
    "\n",
    "##============================================================= \n",
    "    return w3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w3_final=LinearRegression(X2, y2)#这里用的是data2的数据\n",
    "print('The weight vector:\\n',w3_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 岭回归 (Ridge Regression)\n",
    "\n",
    "为提升线性回归模型的稳定性，可考虑如下岭回归(Ridge Regression)模型（有时也被称为脊回归模型）\n",
    "\n",
    "$$E(\\mathbf{w}) = \\|\\mathbf{X}\\mathbf{w}-\\mathbf{y}\\|_2^2+\\lambda\\|\\mathbf{w}\\|_2^2$$\n",
    "\n",
    "其中$\\lambda$为正则化参数，为非负数。上述模型的闭式解为\n",
    "\n",
    "$$ \\mathbf{w}= (\\mathbf{X}^T\\mathbf{X}+\\lambda\\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "**要点 6：**\n",
    "\n",
    "你的任务是**代码实现岭回归的闭式解**。\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###岭回归闭式解###\n",
    "def RidgeRegression(X, y, lam):\n",
    "    ##====================== 在这里填入代码 ======================= \n",
    "\n",
    "    ##======================================= =====================\n",
    "    return w4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w4_final=RidgeRegression(X2, y2,0.01) #这里用的是data2的数据\n",
    "print('The weight vector:\\n',w4_final)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
